{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9272a3a4959479fb31257a96e0d377d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e92fbf6bea574a4288ae7cb46d543a34",
              "IPY_MODEL_1a082a4211e84f7bb9e308cd30a2ea13",
              "IPY_MODEL_89fce7c63515403f883b4dd2481fbd01"
            ],
            "layout": "IPY_MODEL_cba90b71d5ca43acb9b330897ea33e8d"
          }
        },
        "e92fbf6bea574a4288ae7cb46d543a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a05de329cbbd4ec086c08b54afb8fc42",
            "placeholder": "​",
            "style": "IPY_MODEL_39376116ffd14d29acb5519c20c9ae4b",
            "value": "Batches: 100%"
          }
        },
        "1a082a4211e84f7bb9e308cd30a2ea13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa65c346be434fa1afb17d6aa76ce81f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0447725a1c8b4fb3aaa838f747c34e05",
            "value": 1
          }
        },
        "89fce7c63515403f883b4dd2481fbd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001bd3007e624414bbed7a199e69b144",
            "placeholder": "​",
            "style": "IPY_MODEL_3669f03117aa45b4b430902d71647e92",
            "value": " 1/1 [00:06&lt;00:00,  6.01s/it]"
          }
        },
        "cba90b71d5ca43acb9b330897ea33e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05de329cbbd4ec086c08b54afb8fc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39376116ffd14d29acb5519c20c9ae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa65c346be434fa1afb17d6aa76ce81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0447725a1c8b4fb3aaa838f747c34e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "001bd3007e624414bbed7a199e69b144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3669f03117aa45b4b430902d71647e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing (Chunk extraction)"
      ],
      "metadata": {
        "id": "e2ufYt1sdQBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install -U sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install openai\n",
        "!pip install --upgrade openai\n",
        "!pip install translate\n",
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "9tRtBVYBii8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da26adb8-4180-4156-b24c-d7a2be5ffc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.23.22)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.23.22)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from translate) (8.1.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from translate) (4.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from translate) (2.31.0)\n",
            "Collecting libretranslatepy==2.1.1 (from translate)\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2024.2.2)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ee00a6e9939e8570e5fc66001913623a026f28d28a4a6687bdbe65baa5dc3a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import fitz  # PyMuPDF (takes PDF)\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from translate import Translator\n",
        "from langdetect import detect\n",
        "\n",
        "# Designed by: Jad Oubala, Will Kaminski & Sam Bradley\n",
        "\n",
        "# Function to download PDF from a user-inputted URL\n",
        "# Uses the urllib.request.urlretrieve function to fetch the PDF from the url and\n",
        "# save it as a file at output_path.\n",
        "\n",
        "# def download_pdf(url, output_path):\n",
        "    # urllib.request.urlretrieve(url, output_path)\n",
        "\n",
        "# Preprocessing function to clean text\n",
        "# Cleans up the extracted text by removing newlines and extra spaces.\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "# Convert PDF document to text\n",
        "# Opens the PDF using fitz.open (PyMuPDF).\n",
        "# Iterates through the specified page range, extracting text from each page.\n",
        "# Applies the preprocess function to clean up each page's text.\n",
        "# Collects and returns a list of the cleaned text strings, one for each page.\n",
        "\n",
        "def pdf_to_text(path, start_page=1, end_page=None):\n",
        "    doc = fitz.open(path)\n",
        "    total_pages = doc.page_count\n",
        "\n",
        "    if end_page is None or end_page > total_pages:\n",
        "        end_page = total_pages\n",
        "\n",
        "    text_list = []\n",
        "\n",
        "    for i in tqdm(range(start_page-1, end_page), desc=\"Extracting text from PDF\"):\n",
        "        text = doc.load_page(i).get_text(\"text\")\n",
        "        text = preprocess(text)\n",
        "        text_list.append(text)\n",
        "\n",
        "    doc.close()\n",
        "    return text_list\n",
        "\n",
        "# Convert list of texts to smaller chunks\n",
        "# Iterates through the list of preprocessed text strings (texts).\n",
        "# For each text string, splits it into words and then groups into chunks\n",
        "# If the end of a chunk falls short of the word_length and it's not the last\n",
        "# chunk, the remaining words are prepended to the next text string to avoid\n",
        "# having short ending chunk.\n",
        "# Each chunk is prefixed with its page number and enclosed in quotes.\n",
        "\n",
        "def text_to_chunks(texts, word_length=150, start_page=1):\n",
        "    chunks = []\n",
        "    buffer = []\n",
        "\n",
        "    for idx, text in enumerate(texts):\n",
        "        words = text.split(' ')\n",
        "        for word in words:\n",
        "            buffer.append(word)\n",
        "            if len(buffer) >= word_length:\n",
        "                chunk = ' '.join(buffer).strip()\n",
        "                chunks.append(f'Page {idx+start_page}: \"{chunk}\"')\n",
        "                buffer = []\n",
        "\n",
        "        # Handle the remaining buffer if it's long enough\n",
        "        if len(buffer) >= word_length:\n",
        "            chunk = ' '.join(buffer).strip()\n",
        "            chunks.append(f'Page {idx+start_page}: \"{chunk}\"')\n",
        "            buffer = []\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Example usage input file:\n",
        "file_path = '/YOUR/PDF/PATH.pdf'  # If directly uploaded\n",
        "# output_path = 'downloaded_document.pdf'\n",
        "# download_pdf(url, output_path)\n",
        "\n",
        "texts = pdf_to_text(file_path, start_page=1)\n",
        "chunks = text_to_chunks(texts, word_length=150)\n",
        "\n",
        "# Optionally, print or process the chunks\n",
        "        # for chunk in chunks[:5]:  # Print first 5 chunks as a sample\n",
        "        #     print(chunk)\n",
        "\n",
        "# Chunk Embedding:\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Assuming `chunks` is your list of preprocessed text chunks\n",
        "embeddings = model.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = embeddings.shape[1]  # Dimension of embeddings\n",
        "index = faiss.IndexFlatL2(dimension) # L2 distance for similarity\n",
        "index.add(embeddings.astype(np.float32))  # Add embeddings to index\n",
        "\n",
        "\n",
        "# Querying the Index for Relevant Chunks\n",
        "# create function to query the index with a user's question\n",
        "# find the most relevant chunks, and display them:\n",
        "# Also, account for translational logic!\n",
        "\n",
        "def search(query, k=5):\n",
        "\n",
        "    original_language = detect_lang(query)\n",
        "    query_in_english = translate_to_english(query) if original_language != 'en' else query\n",
        "\n",
        "    query_embedding = model.encode([query_in_english])[0].astype(np.float32)\n",
        "    distances, indices = index.search(np.array([query_embedding]), 5)\n",
        "\n",
        "    relevant_chunks = [chunks[idx] for idx in indices[0]]\n",
        "    return relevant_chunks, original_language\n",
        "\n",
        "\n",
        "# Example query (TESTING)\n",
        "    # query = \"Explain the concept of interaction in markets between local producers and local consumers.\"\n",
        "    # results = search(query)\n",
        "\n",
        "    # for result in results:\n",
        "    #     print(result)\n",
        "\n",
        "\n",
        "# TRANSLATION-ADJACENT FUNCTIONS\n",
        "\n",
        "# Translates text safely by splitting it into segments, translating each segment,\n",
        "# and then concatenating the results.\n",
        "\n",
        "def safe_translate(text, from_lang, to_lang, max_length=500):\n",
        "    translator = Translator(to_lang=to_lang, from_lang=from_lang)\n",
        "    # Split text into segments of max_length characters without breaking words\n",
        "    words = text.split()\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_length:  # +1 for space\n",
        "            segments.append(\" \".join(current_segment))\n",
        "            current_segment = [word]\n",
        "            current_length = len(word)\n",
        "        else:\n",
        "            current_segment.append(word)\n",
        "            current_length += len(word) + 1  # +1 for space\n",
        "\n",
        "    # Add the last segment if it's not empty\n",
        "    if current_segment:\n",
        "        segments.append(\" \".join(current_segment))\n",
        "\n",
        "    # Translate each segment\n",
        "    translated_segments = [translator.translate(segment) for segment in segments]\n",
        "\n",
        "    # Combine translated segments\n",
        "    translated_text = \" \".join(translated_segments)\n",
        "    return translated_text\n",
        "\n",
        "def detect_lang(text):\n",
        "    return detect(text)\n",
        "\n",
        "def translate_to_english(text, max_length=500):\n",
        "    detected_language = detect_lang(text)\n",
        "    if detected_language != 'en':\n",
        "        return safe_translate(text, from_lang=detected_language, to_lang='en', max_length=max_length)\n",
        "    return text\n",
        "\n",
        "def translate_from_english(text, target_lang, max_length=500):\n",
        "    if target_lang != 'en':\n",
        "        return safe_translate(text, from_lang='en', to_lang=target_lang, max_length=max_length)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# GPT Integration:\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key='YOUR_API_KEY')\n",
        "\n",
        "\n",
        "# Takes the semantically searched chunks as input and generates a response using\n",
        "# the ChatGPT API\n",
        "def generate_response_from_chunks(user_query, max_tokens=325):\n",
        "    relevant_chunks, original_language = search(user_query)\n",
        "\n",
        "    if original_language != 'en':\n",
        "        translated_query_to_english = translate_to_english(user_query)\n",
        "    else:\n",
        "        translated_query_to_english = user_query  # Use the original query directly if it's already in English\n",
        "\n",
        "\n",
        "    # Start constructing the prompt with more structured guidance\n",
        "    prompt = \"search results:\\n\\n\" + \"\".join([f\"{i+1}. {chunk}\\n\\n\" for i, chunk in enumerate(relevant_chunks)])\n",
        "    prompt += \"Instructions: Compose a comprehensive and succinct reply to the query using the search results given. \" \\\n",
        "              \"Cite each reference using [Page #number] notation (every result has a number at the beginning). \" \\\n",
        "              \"Citation should be done at the end of each sentence. If the search results mention multiple subjects \" \\\n",
        "              \"with the same name, create separate answers for each. Only include information found in the results and \" \\\n",
        "              \"don't add any additional information. Make sure the answer is correct and don't output false content. You should also mention where a given answer might be found in the text if appropriate. Keep answers under around seven sentences.\" \\\n",
        "              \"If the text does not relate to the query, simply state 'Sorry, Lil' Dewey found nothing relevant in the text.'. Don't write 'Answer:' \" \\\n",
        "              \"Directly start and state the answer.\\n\"\n",
        "\n",
        "    prompt += f\"Query: {translated_query_to_english}\\n\\n\"\n",
        "\n",
        "    # Send the prompt to the ChatGPT model using the chat/completions endpoint\n",
        "    response = client.chat.completions.create(model=\"gpt-4\",  # Specify the chat model you're using\n",
        "                                               messages=[\n",
        "                                                   {\"role\": \"system\", \"content\": prompt},\n",
        "                                                   {\"role\": \"user\", \"content\": \"Please provide a response based on the above instructions.\"}\n",
        "                                               ],\n",
        "                                               temperature=0.7,\n",
        "                                               max_tokens=max_tokens,\n",
        "                                               top_p=1.0,\n",
        "                                               frequency_penalty=0.0,\n",
        "                                               presence_penalty=0.0)\n",
        "\n",
        "    # Extracting and returning the text from the response:\n",
        "    generated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "    translated_response = translate_from_english(generated_text, original_language) if original_language != 'en' else generated_text\n",
        "\n",
        "    return translated_response\n",
        "\n",
        "# Example usage\n",
        "# Example user query in a non-English language\n",
        "user_query = \"¿Cuál es el papel que desempeñan las redes generativas adversarias en términos de mejorar la eficacia de los modelos de IA?\"\n",
        "response = generate_response_from_chunks(user_query)\n",
        "print(\"Response:\", response)\n"
      ],
      "metadata": {
        "id": "oUj2emgrdXbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "b9272a3a4959479fb31257a96e0d377d",
            "e92fbf6bea574a4288ae7cb46d543a34",
            "1a082a4211e84f7bb9e308cd30a2ea13",
            "89fce7c63515403f883b4dd2481fbd01",
            "cba90b71d5ca43acb9b330897ea33e8d",
            "a05de329cbbd4ec086c08b54afb8fc42",
            "39376116ffd14d29acb5519c20c9ae4b",
            "aa65c346be434fa1afb17d6aa76ce81f",
            "0447725a1c8b4fb3aaa838f747c34e05",
            "001bd3007e624414bbed7a199e69b144",
            "3669f03117aa45b4b430902d71647e92"
          ]
        },
        "outputId": "52045be2-ae91-4511-bfbb-c0dc2cb5ce83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting text from PDF: 100%|██████████| 9/9 [00:00<00:00, 178.68it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9272a3a4959479fb31257a96e0d377d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Las redes generativas adversarias (GAN) desempeñan un papel fundamental en la mejora de la eficacia de los modelos de IA a través de sus capacidades únicas. Las Gan constan de dos modelos: un modelo generativo G que captura la distribución de datos y un modelo discriminativo D que estima la probabilidad de que una muestra provenga de los datos de entrenamiento en lugar de G [Página 1]. Una de las ventajas clave de las redes adversarias es que pueden representar distribuciones muy nítidas, incluso degeneradas, cuyos métodos se basan en Las cadenas de Markov pueden tener dificultades con [Página 7]. Tampoco requieren una cadena de Markov para el muestreo, lo que puede ser una ventaja sobre otros métodos como el marco de la red estocástica generativa (GSN) [Página 2]. Las Gan están diseñadas para entrenar por retropropagación, una característica que ayuda a mejorar el rendimiento de la retropropagación [Página 2]. Además, los modelos adversarios pueden incorporar funciones en su modelo y no actualizan la red de generadores directamente con ejemplos de datos, sino solo con gradientes que fluyen a través del discriminador [Página 7].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Translation:**"
      ],
      "metadata": {
        "id": "s9ddwIE6ylMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import Translator\n",
        "from langdetect import detect\n",
        "\n",
        "\n",
        "#Get language\n",
        "def detect_lang(text):\n",
        " return detect(text)\n",
        "\n",
        "\n",
        "#For inputs\n",
        "def translate_to_english(text):\n",
        "   #Basically only important one get text language, maybe make outside of function?\n",
        "   detected_language = detect_lang(text)\n",
        "\n",
        "\n",
        "   if detected_language != 'en':\n",
        "       #Traslate text\n",
        "       translator = Translator(to_lang='en', from_lang=detected_language)\n",
        "       translated_text = translator.translate(text)\n",
        "       return translated_text\n",
        "   else:\n",
        "       return text\n",
        "\n",
        "\n",
        "#For outputs\n",
        "def translate_from_english(text):\n",
        "   translator = Translator(to_lang=detect_lang(text1))\n",
        "   translated_text = translator.translate(text)\n",
        "   return translated_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text1 = \"english\"\n",
        "#Have to input this into the LLM instead of whatever the user inputs.\n",
        "translated_text = translate_to_english(text1)\n",
        "\n",
        "\n",
        "#Just for vizualization\n",
        "print(translated_text)\n",
        "\n",
        "\n",
        "output = \"Hello I am\"\n",
        "#Have to output this from the LLM\n",
        "translated_text = translate_from_english(output)\n",
        "\n",
        "\n",
        "#Just for vizualization\n",
        "print(translated_text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kiUyVQklr2YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c743dc-8a8d-42cb-9901-8a08081e5f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English\n",
            "Hallo, ich bin\n"
          ]
        }
      ]
    }
  ]
}