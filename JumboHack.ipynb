{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f07324b9eb1e43f8aa23e30fb8987928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc8e6fc841144535bed4b78de55e421f",
              "IPY_MODEL_cb5b6d56b10b40c49e9191fc950a4c9c",
              "IPY_MODEL_c55f5362a9344309a445015168f5b7e1"
            ],
            "layout": "IPY_MODEL_c33406fb1ac24b2a9b68983ad7be7e92"
          }
        },
        "fc8e6fc841144535bed4b78de55e421f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0a0681f3764f5c98afa02fbcf68461",
            "placeholder": "​",
            "style": "IPY_MODEL_f4eddea9f0fc4986a9c66363267b4f9d",
            "value": "Batches: 100%"
          }
        },
        "cb5b6d56b10b40c49e9191fc950a4c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a710f678644402498559c0e3d9d8ec5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e3e5e68a6ae40c9b96d12f4ad01a808",
            "value": 1
          }
        },
        "c55f5362a9344309a445015168f5b7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bee2375cfd44f52ab00043e7b9c272a",
            "placeholder": "​",
            "style": "IPY_MODEL_8f3cd69cc12546a0ba8b93536c228093",
            "value": " 1/1 [00:05&lt;00:00,  5.22s/it]"
          }
        },
        "c33406fb1ac24b2a9b68983ad7be7e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0a0681f3764f5c98afa02fbcf68461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4eddea9f0fc4986a9c66363267b4f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a710f678644402498559c0e3d9d8ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3e5e68a6ae40c9b96d12f4ad01a808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bee2375cfd44f52ab00043e7b9c272a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3cd69cc12546a0ba8b93536c228093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing (Chunk extraction)"
      ],
      "metadata": {
        "id": "e2ufYt1sdQBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install -U sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install openai\n",
        "!pip install --upgrade openai\n",
        "!pip install translate\n",
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "9tRtBVYBii8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da26adb8-4180-4156-b24c-d7a2be5ffc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.23.22)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.23.22)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from translate) (8.1.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from translate) (4.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from translate) (2.31.0)\n",
            "Collecting libretranslatepy==2.1.1 (from translate)\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2024.2.2)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ee00a6e9939e8570e5fc66001913623a026f28d28a4a6687bdbe65baa5dc3a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import fitz  # PyMuPDF (takes PDF)\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from translate import Translator\n",
        "from langdetect import detect\n",
        "\n",
        "# Function to download PDF from a user-inputted URL\n",
        "# Uses the urllib.request.urlretrieve function to fetch the PDF from the url and\n",
        "# save it as a file at output_path.\n",
        "\n",
        "# def download_pdf(url, output_path):\n",
        "    # urllib.request.urlretrieve(url, output_path)\n",
        "\n",
        "# Preprocessing function to clean text\n",
        "# Cleans up the extracted text by removing newlines and extra spaces.\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "# Convert PDF document to text\n",
        "# Opens the PDF using fitz.open (PyMuPDF).\n",
        "# Iterates through the specified page range, extracting text from each page.\n",
        "# Applies the preprocess function to clean up each page's text.\n",
        "# Collects and returns a list of the cleaned text strings, one for each page.\n",
        "\n",
        "def pdf_to_text(path, start_page=1, end_page=None):\n",
        "    doc = fitz.open(path)\n",
        "    total_pages = doc.page_count\n",
        "\n",
        "    if end_page is None or end_page > total_pages:\n",
        "        end_page = total_pages\n",
        "\n",
        "    text_list = []\n",
        "\n",
        "    for i in tqdm(range(start_page-1, end_page), desc=\"Extracting text from PDF\"):\n",
        "        text = doc.load_page(i).get_text(\"text\")\n",
        "        text = preprocess(text)\n",
        "        text_list.append(text)\n",
        "\n",
        "    doc.close()\n",
        "    return text_list\n",
        "\n",
        "# Convert list of texts to smaller chunks\n",
        "# Iterates through the list of preprocessed text strings (texts).\n",
        "# For each text string, splits it into words and then groups into chunks\n",
        "# If the end of a chunk falls short of the word_length and it's not the last\n",
        "# chunk, the remaining words are prepended to the next text string to avoid\n",
        "# having short ending chunk.\n",
        "# Each chunk is prefixed with its page number and enclosed in quotes.\n",
        "\n",
        "def text_to_chunks(texts, word_length=150, start_page=1):\n",
        "    chunks = []\n",
        "    buffer = []\n",
        "\n",
        "    for idx, text in enumerate(texts):\n",
        "        words = text.split(' ')\n",
        "        for word in words:\n",
        "            buffer.append(word)\n",
        "            if len(buffer) >= word_length:\n",
        "                chunk = ' '.join(buffer).strip()\n",
        "                chunks.append(f'Page {idx+start_page}: \"{chunk}\"')\n",
        "                buffer = []\n",
        "\n",
        "        # Handle the remaining buffer if it's long enough\n",
        "        if len(buffer) >= word_length:\n",
        "            chunk = ' '.join(buffer).strip()\n",
        "            chunks.append(f'Page {idx+start_page}: \"{chunk}\"')\n",
        "            buffer = []\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Example usage input file:\n",
        "file_path = '/content/GANPaper.pdf'  # If directly uploaded\n",
        "# output_path = 'downloaded_document.pdf'\n",
        "# download_pdf(url, output_path)\n",
        "\n",
        "texts = pdf_to_text(file_path, start_page=1)\n",
        "chunks = text_to_chunks(texts, word_length=150)\n",
        "\n",
        "# Optionally, print or process the chunks\n",
        "        # for chunk in chunks[:5]:  # Print first 5 chunks as a sample\n",
        "        #     print(chunk)\n",
        "\n",
        "# Chunk Embedding:\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Assuming `chunks` is your list of preprocessed text chunks\n",
        "embeddings = model.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = embeddings.shape[1]  # Dimension of embeddings\n",
        "index = faiss.IndexFlatL2(dimension) # L2 distance for similarity\n",
        "index.add(embeddings.astype(np.float32))  # Add embeddings to index\n",
        "\n",
        "\n",
        "# Querying the Index for Relevant Chunks\n",
        "# create function to query the index with a user's question\n",
        "# find the most relevant chunks, and display them:\n",
        "# Also, account for translational logic!\n",
        "\n",
        "def search(query, k=5):\n",
        "\n",
        "    original_language = detect_lang(query)\n",
        "    query_in_english = translate_to_english(query) if original_language != 'en' else query\n",
        "\n",
        "    query_embedding = model.encode([query_in_english])[0].astype(np.float32)\n",
        "    distances, indices = index.search(np.array([query_embedding]), 5)\n",
        "\n",
        "    relevant_chunks = [chunks[idx] for idx in indices[0]]\n",
        "    return relevant_chunks, original_language\n",
        "\n",
        "\n",
        "# Example query (TESTING)\n",
        "    # query = \"Explain the concept of interaction in markets between local producers and local consumers.\"\n",
        "    # results = search(query)\n",
        "\n",
        "    # for result in results:\n",
        "    #     print(result)\n",
        "\n",
        "\n",
        "# TRANSLATION-ADJACENT FUNCTIONS\n",
        "\n",
        "# Translates text safely by splitting it into segments, translating each segment,\n",
        "# and then concatenating the results.\n",
        "\n",
        "def safe_translate(text, from_lang, to_lang, max_length=500):\n",
        "    translator = Translator(to_lang=to_lang, from_lang=from_lang)\n",
        "    # Split text into segments of max_length characters without breaking words\n",
        "    words = text.split()\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_length:  # +1 for space\n",
        "            segments.append(\" \".join(current_segment))\n",
        "            current_segment = [word]\n",
        "            current_length = len(word)\n",
        "        else:\n",
        "            current_segment.append(word)\n",
        "            current_length += len(word) + 1  # +1 for space\n",
        "\n",
        "    # Add the last segment if it's not empty\n",
        "    if current_segment:\n",
        "        segments.append(\" \".join(current_segment))\n",
        "\n",
        "    # Translate each segment\n",
        "    translated_segments = [translator.translate(segment) for segment in segments]\n",
        "\n",
        "    # Combine translated segments\n",
        "    translated_text = \" \".join(translated_segments)\n",
        "    return translated_text\n",
        "\n",
        "def detect_lang(text):\n",
        "    return detect(text)\n",
        "\n",
        "def translate_to_english(text, max_length=500):\n",
        "    detected_language = detect_lang(text)\n",
        "    if detected_language != 'en':\n",
        "        return safe_translate(text, from_lang=detected_language, to_lang='en', max_length=max_length)\n",
        "    return text\n",
        "\n",
        "def translate_from_english(text, target_lang, max_length=500):\n",
        "    if target_lang != 'en':\n",
        "        return safe_translate(text, from_lang='en', to_lang=target_lang, max_length=max_length)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# GPT Integration:\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key='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')\n",
        "\n",
        "\n",
        "# akes the semantically searched chunks as input and generates a response using\n",
        "# the ChatGPT API\n",
        "def generate_response_from_chunks(user_query, max_tokens=325):\n",
        "    relevant_chunks, original_language = search(user_query)\n",
        "\n",
        "    if original_language != 'en':\n",
        "        translated_query_to_english = translate_to_english(user_query)\n",
        "    else:\n",
        "        translated_query_to_english = user_query  # Use the original query directly if it's already in English\n",
        "\n",
        "\n",
        "    # Start constructing the prompt with more structured guidance\n",
        "    prompt = \"search results:\\n\\n\" + \"\".join([f\"{i+1}. {chunk}\\n\\n\" for i, chunk in enumerate(relevant_chunks)])\n",
        "    prompt += \"Instructions: Compose a comprehensive and succinct reply to the query using the search results given. \" \\\n",
        "              \"Cite each reference using [Page #number] notation (every result has a number at the beginning). \" \\\n",
        "              \"Citation should be done at the end of each sentence. If the search results mention multiple subjects \" \\\n",
        "              \"with the same name, create separate answers for each. Only include information found in the results and \" \\\n",
        "              \"don't add any additional information. Make sure the answer is correct and don't output false content. You should also mention where a given answer might be found in the text if appropriate. Keep answers under around seven sentences.\" \\\n",
        "              \"If the text does not relate to the query, simply state 'Sorry, Lil' Dewey found nothing relevant in the text.'. Don't write 'Answer:' \" \\\n",
        "              \"Directly start and state the answer.\\n\"\n",
        "\n",
        "    prompt += f\"Query: {translated_query_to_english}\\n\\n\"\n",
        "\n",
        "    # Send the prompt to the ChatGPT model using the chat/completions endpoint\n",
        "    response = client.chat.completions.create(model=\"gpt-4\",  # Specify the chat model you're using\n",
        "                                               messages=[\n",
        "                                                   {\"role\": \"system\", \"content\": prompt},\n",
        "                                                   {\"role\": \"user\", \"content\": \"Please provide a response based on the above instructions.\"}\n",
        "                                               ],\n",
        "                                               temperature=0.7,\n",
        "                                               max_tokens=max_tokens,\n",
        "                                               top_p=1.0,\n",
        "                                               frequency_penalty=0.0,\n",
        "                                               presence_penalty=0.0)\n",
        "\n",
        "    # Extracting and returning the text from the response:\n",
        "    generated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "    translated_response = translate_from_english(generated_text, original_language) if original_language != 'en' else generated_text\n",
        "\n",
        "    return translated_response\n",
        "\n",
        "# Example usage\n",
        "# Example user query in a non-English language\n",
        "user_query = \"¿Cuál es el papel que desempeñan las redes generativas adversarias en términos de mejorar la eficacia de los modelos de IA?\"\n",
        "response = generate_response_from_chunks(user_query)\n",
        "print(\"Response:\", response)\n"
      ],
      "metadata": {
        "id": "oUj2emgrdXbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "f07324b9eb1e43f8aa23e30fb8987928",
            "fc8e6fc841144535bed4b78de55e421f",
            "cb5b6d56b10b40c49e9191fc950a4c9c",
            "c55f5362a9344309a445015168f5b7e1",
            "c33406fb1ac24b2a9b68983ad7be7e92",
            "bf0a0681f3764f5c98afa02fbcf68461",
            "f4eddea9f0fc4986a9c66363267b4f9d",
            "8a710f678644402498559c0e3d9d8ec5",
            "6e3e5e68a6ae40c9b96d12f4ad01a808",
            "9bee2375cfd44f52ab00043e7b9c272a",
            "8f3cd69cc12546a0ba8b93536c228093"
          ]
        },
        "outputId": "71f315d8-4059-4b4b-dab2-002c1a5614f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting text from PDF: 100%|██████████| 9/9 [00:00<00:00, 137.95it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f07324b9eb1e43f8aa23e30fb8987928"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Las redes generativas adversarias (GAN) sirven como un marco para estimar modelos generativos a través de un proceso adversario, entrenando simultáneamente dos modelos: un modelo generativo G que captura la distribución de datos y un modelo discriminativo D que estima la probabilidad de que una muestra provenga de los datos de entrenamiento en lugar de G [Página 1]. Las Gan tienen la ventaja de que no requieren una cadena de Markov para el muestreo y son más capaces de aprovechar unidades lineales por piezas, lo que mejora la rendimiento de la retropropagación [Página 2]. Estas redes pueden representar distribuciones muy nítidas, incluso degeneradas y obtener alguna ventaja estadística de que la red del generador no se actualice directamente con ejemplos de datos, sino solo con gradientes que fluyen a través del discriminador [Página 7]. Las GAN también permiten la implementación de la inferencia aproximada aprendida y cualquier función diferenciable está teóricamente permitida en el diseño de su modelo [Página 7]. Estas características del adversarial generativo contribuyen a mejorar la efectividad de los modelos de IA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Translation:**"
      ],
      "metadata": {
        "id": "s9ddwIE6ylMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import Translator\n",
        "from langdetect import detect\n",
        "\n",
        "\n",
        "#Get language\n",
        "def detect_lang(text):\n",
        " return detect(text)\n",
        "\n",
        "\n",
        "#For inputs\n",
        "def translate_to_english(text):\n",
        "   #Basically only important one get text language, maybe make outside of function?\n",
        "   detected_language = detect_lang(text)\n",
        "\n",
        "\n",
        "   if detected_language != 'en':\n",
        "       #Traslate text\n",
        "       translator = Translator(to_lang='en', from_lang=detected_language)\n",
        "       translated_text = translator.translate(text)\n",
        "       return translated_text\n",
        "   else:\n",
        "       return text\n",
        "\n",
        "\n",
        "#For outputs\n",
        "def translate_from_english(text):\n",
        "   translator = Translator(to_lang=detect_lang(text1))\n",
        "   translated_text = translator.translate(text)\n",
        "   return translated_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text1 = \"english\"\n",
        "#Have to input this into the LLM instead of whatever the user inputs.\n",
        "translated_text = translate_to_english(text1)\n",
        "\n",
        "\n",
        "#Just for vizualization\n",
        "print(translated_text)\n",
        "\n",
        "\n",
        "output = \"Hello I am\"\n",
        "#Have to output this from the LLM\n",
        "translated_text = translate_from_english(output)\n",
        "\n",
        "\n",
        "#Just for vizualization\n",
        "print(translated_text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kiUyVQklr2YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c743dc-8a8d-42cb-9901-8a08081e5f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English\n",
            "Hallo, ich bin\n"
          ]
        }
      ]
    }
  ]
}